# -*- coding: utf-8 -*-
"""word_similarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XutErCzJjyXjz6ZoF4TIGA21bHGlfB3t
"""
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer


class MatrixSimilarity():
	def __init__(self) -> None:
		self.df = pd.read_csv("udemydataset/clean_dataset.csv")
	def count_based(self):
		count = CountVectorizer()
		count_matrix = count.fit_transform(self.df['text_clean'])
		print(count_matrix.shape) # (44554, 47601)
		self.count_based_matrix = cosine_similarity(count_matrix, count_matrix)
	def tfidf_based(self):
		tfidf = TfidfVectorizer()
		tfidf_matrix_train = tfidf.fit_transform(self.df['text_clean'])
		print(tfidf_matrix_train.shape)
		self.tfidf_based_matrix = cosine_simiarity(tfidf_matrix_train,tfidf_matrix_train)
	def bert_based(self):
		model = SentenceTransformer('bert-base-nli-mean-tokens')
		sen = []
		for sent in self.df['text_clean']:
			sen.append(sent)
		sen_embeddings = model.encode(sen)
		print(sen_embeddings.shape)
		new_class = model.encode(self.df['text_clean'])
		print(new_class.shape)
		self.bert_based_matrix = cosine_simiarity(sen_embeddings,sen_embeddings)

# from gensim.models import Word2Vec
# sen = []
# for sent in df['test']:
#   flt = str(sent)
#   sen.append(flt)
# print(sen)
# model = Word2Vec(sen, min_count=1,size= 50,workers=3, window =3, sg = 1)

# model.wv.vectors.shape